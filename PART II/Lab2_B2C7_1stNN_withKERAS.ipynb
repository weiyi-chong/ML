{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab2_B2C7_1stNN_withKERAS.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNT+pR7n/sYMGvuCAS0U8TU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Develop Your First Neural Network With Keras\n","Keras is a powerful and easy-to-use Python library for developing and evaluating deep learning models."],"metadata":{"id":"GEU6E4O9knIh"}},{"cell_type":"markdown","source":["### Step 1: Load Data"],"metadata":{"id":"TY9kyKzDk6xV"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"oSsCSjy4kb1T","executionInfo":{"status":"ok","timestamp":1653555985104,"user_tz":-480,"elapsed":3093,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}}},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import Dense\n","import numpy\n","# fix random seed for reproducibility\n","numpy.random.seed(7) # initialize the random number generator with any seed you like\n","\n","# load pima indians dataset\n","dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n","# split into input and output variables\n","X = dataset[:,0:8]\n","Y = dataset[:,8]"]},{"cell_type":"markdown","source":["### Step 2: Define Model\n","Models in Keras are defined as a sequence of layers. We create a Sequential model and add layers one at a time until we are happy with our network topology.\n","\n","Dense = fully connected layers\n","\n","First hidden layer = 12 neurons, expects 8 input variable, use rectifier (relu) activation function\n","\n","Second hidden layer = 8 neurons, use rectifier (relu) activation function\n","\n","Third layer = 1 neuron to predict the class (onset of diabetes or not), use sigmoid activation function"],"metadata":{"id":"AY935ntnlET-"}},{"cell_type":"code","source":["# create model\n","model = Sequential()\n","model.add(Dense(12, input_dim=8, activation= 'relu' )) # rectifier\n","model.add(Dense(8, activation= 'relu' ))\n","model.add(Dense(1, activation= 'sigmoid' ))"],"metadata":{"id":"ocjUSWX1mLWF","executionInfo":{"status":"ok","timestamp":1653555985923,"user_tz":-480,"elapsed":498,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["### Step 3: Compile Model\n","binary crossentropy = logarithmic loss, which for a binary classification problem is defined in Keras\n","\n","adam = the efficient gradient descent algorithm adam for no other reason that it is an efficient default.\n","\n","collect and report the classification accuracy as the metric because it is a classification problem"],"metadata":{"id":"1wneFyITlHMT"}},{"cell_type":"code","source":["# Compile model\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"],"metadata":{"id":"7ncaSztinQ5G","executionInfo":{"status":"ok","timestamp":1653555988874,"user_tz":-480,"elapsed":429,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### Step 4: Fit Model"],"metadata":{"id":"_EXq-MCtlKAI"}},{"cell_type":"code","source":["# Fit the model\n","model.fit(X, Y, epochs=150, batch_size=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IE2BMNGMocd-","executionInfo":{"status":"ok","timestamp":1653556447533,"user_tz":-480,"elapsed":41335,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"eda8f03a-6c56-41e3-afa6-9c1a832f823a"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5893 - accuracy: 0.6979\n","Epoch 2/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5914 - accuracy: 0.7044\n","Epoch 3/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5908 - accuracy: 0.6979\n","Epoch 4/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5885 - accuracy: 0.7096\n","Epoch 5/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5922 - accuracy: 0.7057\n","Epoch 6/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5884 - accuracy: 0.7005\n","Epoch 7/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5892 - accuracy: 0.7135\n","Epoch 8/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5890 - accuracy: 0.7083\n","Epoch 9/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.7031\n","Epoch 10/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.7057\n","Epoch 11/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5919 - accuracy: 0.6992\n","Epoch 12/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5888 - accuracy: 0.7083\n","Epoch 13/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5911 - accuracy: 0.7044\n","Epoch 14/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5917 - accuracy: 0.6966\n","Epoch 15/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5971 - accuracy: 0.6953\n","Epoch 16/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5929 - accuracy: 0.7018\n","Epoch 17/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5945 - accuracy: 0.7018\n","Epoch 18/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5933 - accuracy: 0.7057\n","Epoch 19/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5884 - accuracy: 0.7044\n","Epoch 20/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5960 - accuracy: 0.7057\n","Epoch 21/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5891 - accuracy: 0.7135\n","Epoch 22/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5877 - accuracy: 0.7057\n","Epoch 23/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5895 - accuracy: 0.7018\n","Epoch 24/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5880 - accuracy: 0.6992\n","Epoch 25/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5931 - accuracy: 0.6992\n","Epoch 26/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5926 - accuracy: 0.7005\n","Epoch 27/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.7070\n","Epoch 28/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5871 - accuracy: 0.7018\n","Epoch 29/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5880 - accuracy: 0.7031\n","Epoch 30/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5904 - accuracy: 0.7031\n","Epoch 31/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5908 - accuracy: 0.7031\n","Epoch 32/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5901 - accuracy: 0.7057\n","Epoch 33/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5913 - accuracy: 0.7044\n","Epoch 34/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5888 - accuracy: 0.7031\n","Epoch 35/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5916 - accuracy: 0.6875\n","Epoch 36/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5924 - accuracy: 0.7005\n","Epoch 37/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5866 - accuracy: 0.7044\n","Epoch 38/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5882 - accuracy: 0.7070\n","Epoch 39/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5881 - accuracy: 0.7070\n","Epoch 40/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5871 - accuracy: 0.7031\n","Epoch 41/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.7109\n","Epoch 42/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5848 - accuracy: 0.7057\n","Epoch 43/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5890 - accuracy: 0.7057\n","Epoch 44/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5901 - accuracy: 0.6979\n","Epoch 45/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5858 - accuracy: 0.7057\n","Epoch 46/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5903 - accuracy: 0.7005\n","Epoch 47/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5841 - accuracy: 0.7096\n","Epoch 48/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5870 - accuracy: 0.6992\n","Epoch 49/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5889 - accuracy: 0.7070\n","Epoch 50/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.7031\n","Epoch 51/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5854 - accuracy: 0.7057\n","Epoch 52/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5875 - accuracy: 0.7083\n","Epoch 53/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5885 - accuracy: 0.7005\n","Epoch 54/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5840 - accuracy: 0.7096\n","Epoch 55/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5887 - accuracy: 0.7070\n","Epoch 56/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.7018\n","Epoch 57/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.7044\n","Epoch 58/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.7096\n","Epoch 59/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6041 - accuracy: 0.7083\n","Epoch 60/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5688 - accuracy: 0.7148\n","Epoch 61/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.7135\n","Epoch 62/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5577 - accuracy: 0.7344\n","Epoch 63/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.7188\n","Epoch 64/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7409\n","Epoch 65/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.7279\n","Epoch 66/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.7292\n","Epoch 67/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7188\n","Epoch 68/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5428 - accuracy: 0.7357\n","Epoch 69/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7279\n","Epoch 70/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7370\n","Epoch 71/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.7448\n","Epoch 72/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.7383\n","Epoch 73/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.7435\n","Epoch 74/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7383\n","Epoch 75/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7357\n","Epoch 76/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7305\n","Epoch 77/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7409\n","Epoch 78/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7513\n","Epoch 79/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.7370\n","Epoch 80/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7396\n","Epoch 81/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7383\n","Epoch 82/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7305\n","Epoch 83/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7435\n","Epoch 84/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7435\n","Epoch 85/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.7370\n","Epoch 86/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7435\n","Epoch 87/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7500\n","Epoch 88/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7409\n","Epoch 89/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7487\n","Epoch 90/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7474\n","Epoch 91/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7422\n","Epoch 92/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7500\n","Epoch 93/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.7396\n","Epoch 94/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7591\n","Epoch 95/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7487\n","Epoch 96/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7461\n","Epoch 97/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7500\n","Epoch 98/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7604\n","Epoch 99/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7552\n","Epoch 100/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7552\n","Epoch 101/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7526\n","Epoch 102/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7526\n","Epoch 103/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7500\n","Epoch 104/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7591\n","Epoch 105/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7500\n","Epoch 106/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7539\n","Epoch 107/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7552\n","Epoch 108/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7461\n","Epoch 109/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7461\n","Epoch 110/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7539\n","Epoch 111/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7513\n","Epoch 112/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7617\n","Epoch 113/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7539\n","Epoch 114/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7487\n","Epoch 115/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7565\n","Epoch 116/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7448\n","Epoch 117/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7552\n","Epoch 118/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7565\n","Epoch 119/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7435\n","Epoch 120/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7552\n","Epoch 121/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7656\n","Epoch 122/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7708\n","Epoch 123/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7500\n","Epoch 124/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7526\n","Epoch 125/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7591\n","Epoch 126/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7552\n","Epoch 127/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7591\n","Epoch 128/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7604\n","Epoch 129/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7695\n","Epoch 130/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.7591\n","Epoch 131/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7539\n","Epoch 132/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7617\n","Epoch 133/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7656\n","Epoch 134/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.7682\n","Epoch 135/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.7773\n","Epoch 136/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.7669\n","Epoch 137/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.7669\n","Epoch 138/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7656\n","Epoch 139/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7539\n","Epoch 140/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7695\n","Epoch 141/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.7591\n","Epoch 142/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.7708\n","Epoch 143/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7734\n","Epoch 144/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7708\n","Epoch 145/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7682\n","Epoch 146/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7695\n","Epoch 147/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7656\n","Epoch 148/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.7708\n","Epoch 149/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7604\n","Epoch 150/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.7643\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fe6a03b7410>"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["### Step 5: Evaluate Model"],"metadata":{"id":"41ShYRaXlMux"}},{"cell_type":"code","source":["# evaluate the model\n","scores = model.evaluate(X, Y)\n","print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"reZNnY5-oudN","executionInfo":{"status":"ok","timestamp":1653556406218,"user_tz":-480,"elapsed":31,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"2f2aab2e-bc10-48a8-e233-d4904a9fab69"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 0s 1ms/step - loss: 0.5841 - accuracy: 0.7083\n","\n","accuracy: 70.83%\n"]}]},{"cell_type":"markdown","source":["### Step 6: Tie it all Together"],"metadata":{"id":"EIM8qxuElPZb"}},{"cell_type":"code","source":["# Create your first MLP in Keras\n","from keras.models import Sequential\n","from keras.layers import Dense\n","import numpy\n","# fix random seed for reproducibility\n","numpy.random.seed(7)\n","# load pima indians dataset\n","dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n","# split into input (X) and output (Y) variables\n","X = dataset[:,0:8]\n","Y = dataset[:,8]\n","# create model\n","model = Sequential()\n","model.add(Dense(12, input_dim=8, activation= 'relu' ))\n","model.add(Dense(8, activation= 'relu' ))\n","model.add(Dense(1, activation= 'sigmoid' ))\n","# Compile model\n","model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n","# Fit the model\n","model.fit(X, Y, epochs=150, batch_size=10)\n","# evaluate the model\n","scores = model.evaluate(X, Y)\n","print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PFvARH1gozyQ","executionInfo":{"status":"ok","timestamp":1653556406215,"user_tz":-480,"elapsed":24860,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"4061bed1-42b6-4c8a-dc92-cd4b04e624ce"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/150\n","77/77 [==============================] - 1s 2ms/step - loss: 5.2594 - accuracy: 0.4688\n","Epoch 2/150\n","77/77 [==============================] - 0s 2ms/step - loss: 1.3320 - accuracy: 0.5625\n","Epoch 3/150\n","77/77 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.5833\n","Epoch 4/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.9315 - accuracy: 0.6133\n","Epoch 5/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.8220 - accuracy: 0.6458\n","Epoch 6/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.8083 - accuracy: 0.6484\n","Epoch 7/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.7608 - accuracy: 0.6471\n","Epoch 8/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.7405 - accuracy: 0.6549\n","Epoch 9/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.7488 - accuracy: 0.6589\n","Epoch 10/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.7198 - accuracy: 0.6419\n","Epoch 11/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.6589\n","Epoch 12/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.7383 - accuracy: 0.6458\n","Epoch 13/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6818 - accuracy: 0.6602\n","Epoch 14/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6580 - accuracy: 0.6589\n","Epoch 15/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.6602\n","Epoch 16/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6553 - accuracy: 0.6602\n","Epoch 17/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6565 - accuracy: 0.6615\n","Epoch 18/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6528 - accuracy: 0.6602\n","Epoch 19/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6387 - accuracy: 0.6693\n","Epoch 20/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6769 - accuracy: 0.6602\n","Epoch 21/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6443 - accuracy: 0.6576\n","Epoch 22/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6440 - accuracy: 0.6654\n","Epoch 23/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6465 - accuracy: 0.6667\n","Epoch 24/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6427 - accuracy: 0.6667\n","Epoch 25/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6654\n","Epoch 26/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6507 - accuracy: 0.6654\n","Epoch 27/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6391 - accuracy: 0.6745\n","Epoch 28/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6458 - accuracy: 0.6693\n","Epoch 29/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6394 - accuracy: 0.6667\n","Epoch 30/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6533 - accuracy: 0.6641\n","Epoch 31/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6556 - accuracy: 0.6719\n","Epoch 32/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6514 - accuracy: 0.6628\n","Epoch 33/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6445 - accuracy: 0.6719\n","Epoch 34/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6384 - accuracy: 0.6732\n","Epoch 35/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6398 - accuracy: 0.6680\n","Epoch 36/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6357 - accuracy: 0.6706\n","Epoch 37/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6375 - accuracy: 0.6706\n","Epoch 38/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6364 - accuracy: 0.6680\n","Epoch 39/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6379 - accuracy: 0.6771\n","Epoch 40/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6359 - accuracy: 0.6706\n","Epoch 41/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6380 - accuracy: 0.6745\n","Epoch 42/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6441 - accuracy: 0.6628\n","Epoch 43/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6281 - accuracy: 0.6771\n","Epoch 44/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6304 - accuracy: 0.6706\n","Epoch 45/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6283 - accuracy: 0.6732\n","Epoch 46/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6286 - accuracy: 0.6784\n","Epoch 47/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6363 - accuracy: 0.6745\n","Epoch 48/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6350 - accuracy: 0.6641\n","Epoch 49/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.6758\n","Epoch 50/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6262 - accuracy: 0.6758\n","Epoch 51/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6246 - accuracy: 0.6797\n","Epoch 52/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6243 - accuracy: 0.6810\n","Epoch 53/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6240 - accuracy: 0.6758\n","Epoch 54/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6268 - accuracy: 0.6732\n","Epoch 55/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6247 - accuracy: 0.6706\n","Epoch 56/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6245 - accuracy: 0.6719\n","Epoch 57/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6299 - accuracy: 0.6771\n","Epoch 58/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6255 - accuracy: 0.6771\n","Epoch 59/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6227 - accuracy: 0.6771\n","Epoch 60/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6220 - accuracy: 0.6732\n","Epoch 61/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6203 - accuracy: 0.6836\n","Epoch 62/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6212 - accuracy: 0.6836\n","Epoch 63/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6216 - accuracy: 0.6797\n","Epoch 64/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6771\n","Epoch 65/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6234 - accuracy: 0.6797\n","Epoch 66/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.6784\n","Epoch 67/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6229 - accuracy: 0.6758\n","Epoch 68/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6210 - accuracy: 0.6771\n","Epoch 69/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6289 - accuracy: 0.6758\n","Epoch 70/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6191 - accuracy: 0.6823\n","Epoch 71/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6191 - accuracy: 0.6797\n","Epoch 72/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6206 - accuracy: 0.6758\n","Epoch 73/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6198 - accuracy: 0.6784\n","Epoch 74/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6275 - accuracy: 0.6732\n","Epoch 75/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6209 - accuracy: 0.6745\n","Epoch 76/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6221 - accuracy: 0.6758\n","Epoch 77/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6165 - accuracy: 0.6849\n","Epoch 78/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6199 - accuracy: 0.6784\n","Epoch 79/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6220 - accuracy: 0.6810\n","Epoch 80/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.6810\n","Epoch 81/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6191 - accuracy: 0.6797\n","Epoch 82/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6184 - accuracy: 0.6771\n","Epoch 83/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6174 - accuracy: 0.6745\n","Epoch 84/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6161 - accuracy: 0.6823\n","Epoch 85/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6157 - accuracy: 0.6745\n","Epoch 86/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6136 - accuracy: 0.6823\n","Epoch 87/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6163 - accuracy: 0.6823\n","Epoch 88/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6100 - accuracy: 0.6849\n","Epoch 89/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6057 - accuracy: 0.6875\n","Epoch 90/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6080 - accuracy: 0.6862\n","Epoch 91/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6073 - accuracy: 0.6875\n","Epoch 92/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6063 - accuracy: 0.6849\n","Epoch 93/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6038 - accuracy: 0.6940\n","Epoch 94/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6033 - accuracy: 0.6862\n","Epoch 95/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6084 - accuracy: 0.6992\n","Epoch 96/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6086 - accuracy: 0.6914\n","Epoch 97/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5999 - accuracy: 0.7005\n","Epoch 98/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6088 - accuracy: 0.6901\n","Epoch 99/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6083 - accuracy: 0.6940\n","Epoch 100/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6048 - accuracy: 0.6979\n","Epoch 101/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5977 - accuracy: 0.6940\n","Epoch 102/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6006 - accuracy: 0.6914\n","Epoch 103/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6033 - accuracy: 0.7005\n","Epoch 104/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6029 - accuracy: 0.6914\n","Epoch 105/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5936 - accuracy: 0.6966\n","Epoch 106/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6029 - accuracy: 0.6992\n","Epoch 107/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.6940\n","Epoch 108/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5992 - accuracy: 0.6940\n","Epoch 109/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6005 - accuracy: 0.6940\n","Epoch 110/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5943 - accuracy: 0.6953\n","Epoch 111/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6012 - accuracy: 0.6940\n","Epoch 112/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5945 - accuracy: 0.6992\n","Epoch 113/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6043 - accuracy: 0.6927\n","Epoch 114/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5944 - accuracy: 0.7005\n","Epoch 115/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5948 - accuracy: 0.6927\n","Epoch 116/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5946 - accuracy: 0.7018\n","Epoch 117/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5960 - accuracy: 0.6966\n","Epoch 118/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5952 - accuracy: 0.6979\n","Epoch 119/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5951 - accuracy: 0.7044\n","Epoch 120/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6055 - accuracy: 0.6953\n","Epoch 121/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5959 - accuracy: 0.6927\n","Epoch 122/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5959 - accuracy: 0.7005\n","Epoch 123/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5906 - accuracy: 0.7109\n","Epoch 124/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5965 - accuracy: 0.6966\n","Epoch 125/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5931 - accuracy: 0.6992\n","Epoch 126/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5984 - accuracy: 0.6940\n","Epoch 127/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5911 - accuracy: 0.7070\n","Epoch 128/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5971 - accuracy: 0.6966\n","Epoch 129/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5957 - accuracy: 0.6966\n","Epoch 130/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5932 - accuracy: 0.6979\n","Epoch 131/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5890 - accuracy: 0.7018\n","Epoch 132/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5999 - accuracy: 0.6992\n","Epoch 133/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5893 - accuracy: 0.7044\n","Epoch 134/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5921 - accuracy: 0.7018\n","Epoch 135/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5896 - accuracy: 0.7057\n","Epoch 136/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5935 - accuracy: 0.6992\n","Epoch 137/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5906 - accuracy: 0.7044\n","Epoch 138/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5924 - accuracy: 0.7005\n","Epoch 139/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6236 - accuracy: 0.7005\n","Epoch 140/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5951 - accuracy: 0.7005\n","Epoch 141/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5957 - accuracy: 0.6979\n","Epoch 142/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5909 - accuracy: 0.6979\n","Epoch 143/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.6992\n","Epoch 144/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5890 - accuracy: 0.6966\n","Epoch 145/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.7031\n","Epoch 146/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5911 - accuracy: 0.6992\n","Epoch 147/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5926 - accuracy: 0.7005\n","Epoch 148/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5903 - accuracy: 0.6966\n","Epoch 149/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5897 - accuracy: 0.7005\n","Epoch 150/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5898 - accuracy: 0.7044\n","24/24 [==============================] - 0s 2ms/step - loss: 0.5841 - accuracy: 0.7083\n","\n","accuracy: 70.83%\n"]}]}]}