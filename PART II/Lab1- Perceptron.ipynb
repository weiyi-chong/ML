{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab1- Perceptron.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOkvspkG/i4f51NKArVSz2e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["##10.2.1 Making Predictions\n","activation = bias + sum(weight*x)"],"metadata":{"id":"2B9Bf_UVcb1E"}},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c7whPDWpcDWo","executionInfo":{"status":"ok","timestamp":1652971610163,"user_tz":-480,"elapsed":804,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"9f69b9b6-8eb4-43b5-a06a-9b28400ac5d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Expected=0, Predicted=0\n","Expected=0, Predicted=0\n","Expected=0, Predicted=0\n","Expected=0, Predicted=0\n","Expected=0, Predicted=0\n","Expected=1, Predicted=1\n","Expected=1, Predicted=1\n","Expected=1, Predicted=1\n","Expected=1, Predicted=1\n","Expected=1, Predicted=1\n"]}],"source":["# Example of making predictions\n","\n","# Make a prediction with weights\n","def predict(row, weights):\n","  activation = weights[0]   # sum\n","  for i in range(len(row)-1): #3-1 = 2\n","    activation += weights[i+1] * row[i] \n","    # i = 0, weights[i+1] = w1, row[i] = x1\n","    # i = 1, weights[i+1] = w2, row[i] = x2\n","  return 1.0 if activation >= 0.0 else 0.0\n","\n","# test predictions [X1, X2, Y]\n","dataset = [[2.7810836,2.550537003,0],\n","[1.465489372,2.362125076,0],\n","[3.396561688,4.400293529,0],\n","[1.38807019,1.850220317,0],\n","[3.06407232,3.005305973,0],\n","[7.627531214,2.759262235,1],\n","[5.332441248,2.088626775,1],\n","[6.922596716,1.77106367,1],\n","[8.675418651,-0.242068655,1],\n","[7.673756466,3.508563011,1]]\n","\n","# weights = [bias, w1, w2]\n","weights = [-0.1, 0.20653640140000007, -0.23418117710000003]\n","\n","# each row in the data (repeat 10 times)\n","for row in dataset: \n","  prediction = predict(row, weights)\n","  print(\"Expected=%d, Predicted=%d\" % (row[-1], prediction))"]},{"cell_type":"markdown","source":["## 10.2.2 Training Network Weights\n","Learning Rate: Used to limit the amount each weight is corrected each time it is\n","updated.\n","\n","Epochs: The number of times to run through the training data while updating the weight."],"metadata":{"id":"-SLr66kseD-1"}},{"cell_type":"code","source":["# Estimate Perceptron weights using stochastic gradient descent\n","# train_weights = calculates weight values for a training dataset \n","# using stochastic gradient descent.\n","def train_weights(train, l_rate, n_epoch):\n","  weights = [0.0 for i in range(len(train[0]))]\n","  for epoch in range(n_epoch):\n","    sum_error = 0.0\n","    for row in train:\n","      prediction = predict(row, weights)\n","      error = row[-1] - prediction\n","      sum_error += error**2\n","      weights[0] = weights[0] + l_rate * error\n","      for i in range(len(row)-1):\n","        weights[i+1] = weights[i+1] + l_rate * error * row[i]\n","    print( '>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n","  return weights"],"metadata":{"id":"QJTF4DtbeRge","executionInfo":{"status":"ok","timestamp":1652971610920,"user_tz":-480,"elapsed":4,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["# Example of training weights\n","\n","# Make a prediction with weights\n","def predict(row, weights):\n","  activation = weights[0]   # sum\n","  for i in range(len(row)-1): #3-1 = 2\n","    activation += weights[i+1] * row[i] \n","    # i = 0, weights[i+1] = w1, row[i] = x1\n","    # i = 1, weights[i+1] = w2, row[i] = x2\n","  return 1.0 if activation >= 0.0 else 0.0\n","\n","#Estimate Perceptron weights using stochastic gradient descent\n","def train_weights(train, l_rate, n_epoch):\n","  weights = [0.0 for i in range(len(train[0]))]\n","  for epoch in range(n_epoch):\n","    sum_error = 0.0\n","    for row in train:\n","      prediction = predict(row, weights)\n","      # error = expected - predicted\n","      error = row[-1] - prediction\n","      sum_error += error**2\n","      weights[0] = weights[0] + l_rate * error\n","      for i in range(len(row)-1):\n","        weights[i + 1] = weights[i + 1] + l_rate * error * row[i]\n","    print( '>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n","  return weights\n","\n","# Calculate weights [x1, x2, y]\n","dataset = [[2.7810836,2.550537003,0],\n","  [1.465489372,2.362125076,0],\n","  [3.396561688,4.400293529,0],\n","  [1.38807019,1.850220317,0],\n","  [3.06407232,3.005305973,0],\n","  [7.627531214,2.759262235,1],\n","  [5.332441248,2.088626775,1],\n","  [6.922596716,1.77106367,1],\n","  [8.675418651,-0.242068655,1],\n","  [7.673756466,3.508563011,1]]\n","\n","l_rate = 0.1 # learning rate\n","n_epoch = 5  # number of epoch\n","weights = train_weights(dataset, l_rate, n_epoch)\n","print(weights)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"da7qBU5TfxSt","executionInfo":{"status":"ok","timestamp":1652971610921,"user_tz":-480,"elapsed":4,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"d8a94976-beec-4fbe-a77c-6d7487f71fc2"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":[">epoch=0, lrate=0.100, error=2.000\n",">epoch=1, lrate=0.100, error=1.000\n",">epoch=2, lrate=0.100, error=0.000\n",">epoch=3, lrate=0.100, error=0.000\n",">epoch=4, lrate=0.100, error=0.000\n","[-0.1, 0.20653640140000007, -0.23418117710000003]\n"]}]},{"cell_type":"markdown","source":["## 10.2.3 Sonar Case Study"],"metadata":{"id":"I5Uo6BEFg6hJ"}},{"cell_type":"code","source":["# Perceptron Algorithm on the Sonar Dataset\n","from random import seed\n","from random import randrange\n","from csv import reader\n","\n","# Load a CSV file\n","def load_csv(filename):\n","  dataset = list()\n","  with open(filename, 'r') as file:\n","    csv_reader = reader(file)\n","    for row in csv_reader:\n","      if not row:\n","        continue\n","      dataset.append(row)\n","  return dataset\n","\n","# Convert string column to float\n","def str_column_to_float(dataset, column):\n","  for row in dataset:\n","    row[column] = float(row[column].strip())\n","\n","# Convert string column to integer\n","def str_column_to_int(dataset, column):\n","  class_values = [row[column] for row in dataset]\n","  unique = set(class_values)\n","  lookup = dict()\n","  for i, value in enumerate(unique):\n","    lookup[value] = i\n","  for row in dataset:\n","    row[column] = lookup[row[column]]\n","  return lookup\n","\n","# Split a dataset into k folds\n","def cross_validation_split(dataset, n_folds):\n","  dataset_split = list()\n","  dataset_copy = list(dataset)\n","  fold_size = int(len(dataset)/ n_folds)\n","  for _ in range(n_folds):\n","    fold = list()\n","    while len(fold) < fold_size:\n","      index = randrange(len(dataset_copy))\n","      fold.append(dataset_copy.pop(index))\n","    dataset_split.append(fold)\n","  return dataset_split\n","\n","# Calculate accuracy percentage\n","def accuracy_metric(actual, predicted):\n","  correct = 0\n","  for i in range(len(actual)):\n","    if actual[i] == predicted[i]:\n","      correct += 1\n","  return correct / float(len(actual)) * 100.0\n","\n","# Evaluate an algorithm using a cross validation split\n","def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n","  folds = cross_validation_split(dataset, n_folds)\n","  scores = list()\n","  for fold in folds:\n","    train_set = list(folds)\n","    train_set.remove(fold)\n","    train_set = sum(train_set, [])\n","    test_set = list()\n","    for row in fold:\n","      row_copy = list(row)\n","      test_set.append(row_copy)\n","      row_copy[-1] = None\n","    predicted = algorithm(train_set, test_set, *args)\n","    actual = [row[-1] for row in fold]\n","    accuracy = accuracy_metric(actual, predicted)\n","    scores.append(accuracy)\n","  return scores\n","\n","# Make a prediction with weights\n","def predict(row, weights):\n","  activation = weights[0]   # sum\n","  for i in range(len(row)-1): #3-1 = 2\n","    activation += weights[i+1] * row[i] \n","    # i = 0, weights[i+1] = w1, row[i] = x1\n","    # i = 1, weights[i+1] = w2, row[i] = x2\n","  return 1.0 if activation >= 0.0 else 0.0\n","\n","#Estimate Perceptron weights using stochastic gradient descent\n","def train_weights(train, l_rate, n_epoch):\n","  weights = [0.0 for i in range(len(train[0]))]\n","  for _ in range(n_epoch):\n","    for row in train:\n","      prediction = predict(row, weights)\n","      # error = expected - predicted\n","      error = row[-1] - prediction\n","      weights[0] = weights[0] + l_rate * error\n","      for i in range(len(row)-1):\n","        weights[i + 1] = weights[i + 1] + l_rate * error * row[i]\n","  return weights\n","\n","# Perceptron Algorithm With Stochastic Gradient Descent\n","def perceptron(train, test, l_rate, n_epoch):\n","  predictions = list()\n","  weights = train_weights(train, l_rate, n_epoch)\n","  for row in test:\n","    prediction = predict(row, weights)\n","    predictions.append(prediction)\n","  return(predictions)\n","\n","# Test the Perceptron algorithm on the sonar dataset\n","seed(1)\n","\n","# load and prepare data\n","learning_rate = [0.01, 0.001, 0.1]\n","epoch = [500, 10]\n","for e in epoch:\n","  print('Number of epoch: ', e)\n","  print('------------------------------------------------------------------')\n","  for x in learning_rate:\n","    filename = 'sonar.all-data.csv'\n","    dataset = load_csv(filename)\n","    for i in range(len(dataset[0])-1):\n","      str_column_to_float(dataset, i)\n","\n","    # convert string class to integers\n","    str_column_to_int(dataset, len(dataset[0])-1)\n","\n","  # evaluate algorithm\n","    n_folds = 3 # each fold 208/3 = 69.3 records to be evaluated each iteration\n","    l_rate = x # learning rate\n","    n_epoch = e\n","    scores = evaluate_algorithm(dataset, perceptron, n_folds, l_rate, n_epoch)\n","    print('Learning rate: ', x)\n","    print('Scores: %s' % scores)\n","    print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))), '\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e90oi4rxg-mC","executionInfo":{"status":"ok","timestamp":1652973938748,"user_tz":-480,"elapsed":12326,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"d366b101-53e8-4db7-b6b5-faa5839ebefa"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of epoch:  500\n","------------------------------------------------------------------\n","Learning rate:  0.01\n","Scores: [76.81159420289855, 69.56521739130434, 72.46376811594203]\n","Mean Accuracy: 72.947% \n","\n","Learning rate:  0.001\n","Scores: [72.46376811594203, 69.56521739130434, 72.46376811594203]\n","Mean Accuracy: 71.498% \n","\n","Learning rate:  0.1\n","Scores: [72.46376811594203, 79.71014492753623, 73.91304347826086]\n","Mean Accuracy: 75.362% \n","\n","Number of epoch:  10\n","------------------------------------------------------------------\n","Learning rate:  0.01\n","Scores: [57.971014492753625, 71.01449275362319, 66.66666666666666]\n","Mean Accuracy: 65.217% \n","\n","Learning rate:  0.001\n","Scores: [63.76811594202898, 63.76811594202898, 79.71014492753623]\n","Mean Accuracy: 69.082% \n","\n","Learning rate:  0.1\n","Scores: [71.01449275362319, 59.42028985507246, 78.26086956521739]\n","Mean Accuracy: 69.565% \n","\n"]}]}]}