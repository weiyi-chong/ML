{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab3_B2C19_CNN_Implementation.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNokp9Dy/hz5GVLeCw8LDi2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["##19.2 Loading the MNIST dataset in Keras"],"metadata":{"id":"AhjxmRZ0qOTh"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"CcjSdIIOpYRC","colab":{"base_uri":"https://localhost:8080/","height":268},"executionInfo":{"status":"ok","timestamp":1654166058113,"user_tz":-480,"elapsed":5331,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"64310926-4be8-4e72-a291-0fee8aa5968e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 4 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["# Plot ad hoc mnist instances\n","from keras.datasets import mnist\n","import matplotlib.pyplot as plt\n","\n","# load (downloaded if needed) the MNIST dataset\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","# plot 4 images as gray scale\n","plt.subplot(221)\n","plt.imshow(X_train[0], cmap=plt.get_cmap( 'gray' ))\n","plt.subplot(222)\n","plt.imshow(X_train[1], cmap=plt.get_cmap( 'gray' ))\n","plt.subplot(223)\n","plt.imshow(X_train[2], cmap=plt.get_cmap( 'gray' ))\n","plt.subplot(224)\n","plt.imshow(X_train[3], cmap=plt.get_cmap( 'gray' ))\n","\n","# show the plot\n","plt.show()"]},{"cell_type":"markdown","source":["##19.3 Baseline Model with Multilayer Perceptrons\n","simple Multilayer Perceptron model that achieves an error rate of approximately 1.73%."],"metadata":{"id":"ujVGyr_uq0bX"}},{"cell_type":"markdown","source":["###Step1: Import Classes and Function"],"metadata":{"id":"ujI4zmIPq6a3"}},{"cell_type":"code","source":["import numpy\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.utils import np_utils"],"metadata":{"id":"ru0x4bIXq_4z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Step2: Initialize the random number generator"],"metadata":{"id":"iLZ4HC9yrLLR"}},{"cell_type":"code","source":["# fix random seed for reproducibility\n","seed = 7\n","numpy.random.seed(seed)"],"metadata":{"id":"-lFrUQoPrQdB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Step3: Load the MNIST Dataset"],"metadata":{"id":"CmhKTQkBrUMl"}},{"cell_type":"code","source":["# load data\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()"],"metadata":{"id":"q4Q6uqVxrYlI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Step4: Prepare MNIST Dataset for modelling"],"metadata":{"id":"l6NDzYh0rcFZ"}},{"cell_type":"code","source":["# flatten 28*28 images to a 784 vector for each image\n","num_pixels = X_train.shape[1] * X_train.shape[2]\n","X_train = X_train.reshape(X_train.shape[0], num_pixels).astype( 'float32' )\n","X_test = X_test.reshape(X_test.shape[0], num_pixels).astype( 'float32' )"],"metadata":{"id":"5rYkGC41rjoQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Step5: Normalize Pixel Values"],"metadata":{"id":"1uBV7HDwroDi"}},{"cell_type":"code","source":["# normalize inputs from 0-255 to 0-1\n","X_train = X_train / 255\n","X_test = X_test / 255"],"metadata":{"id":"zv-q4At8ruOj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Step6: One Hot Encode the Output Variable"],"metadata":{"id":"ShuKxETfrxoK"}},{"cell_type":"code","source":["# one hot encode outputs\n","y_train = np_utils.to_categorical(y_train)\n","y_test = np_utils.to_categorical(y_test)\n","num_classes = y_test.shape[1]"],"metadata":{"id":"i-JEXvJlr4uJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Step7: Define and Compile the Baseline Model"],"metadata":{"id":"P-ZYl6rQr9wC"}},{"cell_type":"code","source":["# define baseline model\n","def baseline_model():\n","  # create model\n","  model = Sequential()\n","  model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer= 'normal' ,activation= 'relu' ))\n","  model.add(Dense(num_classes, kernel_initializer= 'normal' , activation= 'softmax' ))\n","  # Compile model\n","  model.compile(loss= 'categorical_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n","  return model"],"metadata":{"id":"dVrRPLaFsE7S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Step8: Evaluate the Baseline Model"],"metadata":{"id":"lUmf3tlKsVGQ"}},{"cell_type":"code","source":["# build the model\n","model = baseline_model()\n","# Fit the model\n","model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n","# Final evaluation of the model\n","scores = model.evaluate(X_test, y_test, verbose=0)\n","print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"],"metadata":{"id":"9sYyJsI9sZaM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654166144223,"user_tz":-480,"elapsed":85086,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"357b261d-8048-4e37-b2a3-36100ef3a2ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","300/300 - 10s - loss: 0.2815 - accuracy: 0.9206 - val_loss: 0.1347 - val_accuracy: 0.9599 - 10s/epoch - 33ms/step\n","Epoch 2/10\n","300/300 - 7s - loss: 0.1124 - accuracy: 0.9675 - val_loss: 0.0963 - val_accuracy: 0.9719 - 7s/epoch - 24ms/step\n","Epoch 3/10\n","300/300 - 4s - loss: 0.0715 - accuracy: 0.9788 - val_loss: 0.0838 - val_accuracy: 0.9744 - 4s/epoch - 15ms/step\n","Epoch 4/10\n","300/300 - 5s - loss: 0.0505 - accuracy: 0.9855 - val_loss: 0.0700 - val_accuracy: 0.9766 - 5s/epoch - 16ms/step\n","Epoch 5/10\n","300/300 - 5s - loss: 0.0361 - accuracy: 0.9897 - val_loss: 0.0627 - val_accuracy: 0.9799 - 5s/epoch - 16ms/step\n","Epoch 6/10\n","300/300 - 5s - loss: 0.0258 - accuracy: 0.9935 - val_loss: 0.0614 - val_accuracy: 0.9808 - 5s/epoch - 16ms/step\n","Epoch 7/10\n","300/300 - 5s - loss: 0.0196 - accuracy: 0.9952 - val_loss: 0.0582 - val_accuracy: 0.9812 - 5s/epoch - 15ms/step\n","Epoch 8/10\n","300/300 - 5s - loss: 0.0160 - accuracy: 0.9960 - val_loss: 0.0601 - val_accuracy: 0.9814 - 5s/epoch - 16ms/step\n","Epoch 9/10\n","300/300 - 4s - loss: 0.0115 - accuracy: 0.9973 - val_loss: 0.0576 - val_accuracy: 0.9822 - 4s/epoch - 15ms/step\n","Epoch 10/10\n","300/300 - 4s - loss: 0.0087 - accuracy: 0.9984 - val_loss: 0.0617 - val_accuracy: 0.9807 - 4s/epoch - 15ms/step\n","Baseline Error: 1.93%\n"]}]},{"cell_type":"markdown","source":["### FULL CODE"],"metadata":{"id":"V4EFzNsLseBo"}},{"cell_type":"code","source":["# Baseline MLP for MNIST dataset\n","import numpy\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.utils import np_utils\n","\n","# fix random seed for reproducibility\n","seed = 7\n","numpy.random.seed(seed)\n","\n","# load data\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","# flatten 28*28 images to a 784 vector for each image\n","num_pixels = X_train.shape[1] * X_train.shape[2]\n","X_train = X_train.reshape(X_train.shape[0], num_pixels).astype( 'float32' )\n","X_test = X_test.reshape(X_test.shape[0], num_pixels).astype( 'float32' )\n","\n","# normalize inputs from 0-255 to 0-1\n","X_train = X_train / 255\n","X_test = X_test / 255\n","\n","# one hot encode outputs\n","y_train = np_utils.to_categorical(y_train)\n","y_test = np_utils.to_categorical(y_test)\n","num_classes = y_test.shape[1]\n","\n","# define baseline model\n","def baseline_model():\n","  # create model\n","  model = Sequential()\n","  model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer= 'normal' ,activation= 'relu' ))\n","  model.add(Dense(num_classes, kernel_initializer= 'normal' , activation= 'softmax' ))\n","\n","  # Compile model\n","  model.compile(loss= 'categorical_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n","  return model\n","\n","# build the model\n","model = baseline_model()\n","\n","# Fit the model\n","model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n","\n","# Final evaluation of the model\n","scores = model.evaluate(X_test, y_test, verbose=0)\n","print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"],"metadata":{"id":"cyB39Ilmsgzz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654166228719,"user_tz":-480,"elapsed":84502,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"616bfb1c-682c-4bdc-e7f0-2ff6d6bc3248"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","300/300 - 5s - loss: 0.2799 - accuracy: 0.9219 - val_loss: 0.1398 - val_accuracy: 0.9597 - 5s/epoch - 17ms/step\n","Epoch 2/10\n","300/300 - 5s - loss: 0.1104 - accuracy: 0.9681 - val_loss: 0.0986 - val_accuracy: 0.9710 - 5s/epoch - 15ms/step\n","Epoch 3/10\n","300/300 - 5s - loss: 0.0714 - accuracy: 0.9791 - val_loss: 0.0743 - val_accuracy: 0.9771 - 5s/epoch - 16ms/step\n","Epoch 4/10\n","300/300 - 5s - loss: 0.0494 - accuracy: 0.9855 - val_loss: 0.0705 - val_accuracy: 0.9781 - 5s/epoch - 15ms/step\n","Epoch 5/10\n","300/300 - 5s - loss: 0.0354 - accuracy: 0.9899 - val_loss: 0.0627 - val_accuracy: 0.9806 - 5s/epoch - 16ms/step\n","Epoch 6/10\n","300/300 - 5s - loss: 0.0257 - accuracy: 0.9934 - val_loss: 0.0642 - val_accuracy: 0.9807 - 5s/epoch - 16ms/step\n","Epoch 7/10\n","300/300 - 5s - loss: 0.0190 - accuracy: 0.9956 - val_loss: 0.0602 - val_accuracy: 0.9799 - 5s/epoch - 17ms/step\n","Epoch 8/10\n","300/300 - 4s - loss: 0.0155 - accuracy: 0.9962 - val_loss: 0.0643 - val_accuracy: 0.9799 - 4s/epoch - 15ms/step\n","Epoch 9/10\n","300/300 - 4s - loss: 0.0116 - accuracy: 0.9973 - val_loss: 0.0616 - val_accuracy: 0.9806 - 4s/epoch - 15ms/step\n","Epoch 10/10\n","300/300 - 4s - loss: 0.0079 - accuracy: 0.9987 - val_loss: 0.0611 - val_accuracy: 0.9807 - 4s/epoch - 15ms/step\n","Baseline Error: 1.93%\n"]}]},{"cell_type":"markdown","source":["##19.4 Simple Convolutional Neural Network for MNIST"],"metadata":{"id":"mtqa5zHGs-VN"}},{"cell_type":"markdown","source":["###Step1: Import Classes and Functions"],"metadata":{"id":"tTRa0dystEbd"}},{"cell_type":"code","source":["import numpy\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import Flatten\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.utils import np_utils\n","\n","# fix dimension ordering issue\n","from keras import backend as K\n","#The latest version has replaced the image_dim_ordering to image_data_format.\n","#K.set_image_dim_ordering( 'th' )\n","#channel_last = (batch_size, height, width, channels) --> tf\n","K.set_image_data_format('channels_last')"],"metadata":{"id":"xZNpbjJHtIh9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Step2: Seed Random Number Generator"],"metadata":{"id":"wYxVPS8tHxqS"}},{"cell_type":"code","source":["# fix random seed for reproducibility\n","seed = 7\n","numpy.random.seed(seed)"],"metadata":{"id":"a5DXO3X0H23w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Step3: Load Dataset and Separate Into Train and Test Sets"],"metadata":{"id":"RbIJKaH7H7Pr"}},{"cell_type":"code","source":["# load data\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","# change to(batch_size, height, width, channels) --> tf\n","# height = 1, width = 28, channels=28\n","# reshape to be [samples][channels][width][height]\n","X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype( 'float32' )\n","X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype( 'float32' )"],"metadata":{"id":"4nj347DfIBR7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Step4: Normalize and One hot encode"],"metadata":{"id":"P7nqXI7zIIBQ"}},{"cell_type":"code","source":["# normalize inputs from 0-255 to 0-1\n","X_train = X_train / 255\n","X_test = X_test / 255\n","\n","# one hot encode outputs\n","y_train = np_utils.to_categorical(y_train)\n","y_test = np_utils.to_categorical(y_test)\n","num_classes = y_test.shape[1]"],"metadata":{"id":"JhGZfX5MIL-W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Step5: Define and Compile CNN model"],"metadata":{"id":"zSSHF4UBIQzb"}},{"cell_type":"code","source":["def baseline_model():\n","  # create model\n","  model = Sequential()\n","  # change to(batch_size, height, width, channels) --> tf\n","  # height = 1, width = 28, channels=28\n","  #model.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation= 'relu' )) --> this is channels_first, th\n","  model.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation= 'relu' ))\n","  model.add(MaxPooling2D(pool_size=(2, 2)))\n","  model.add(Dropout(0.2))\n","  model.add(Flatten())\n","  model.add(Dense(128, activation= 'relu' ))\n","  model.add(Dense(num_classes, activation= 'softmax' ))\n","  # Compile model\n","  model.compile(loss= 'categorical_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n","  return model"],"metadata":{"id":"LXuOmFY3IV2p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Step6: Fit and Evaluate the CNN Model"],"metadata":{"id":"zy6d2yrMIdLo"}},{"cell_type":"code","source":["# build the model\n","model = baseline_model()\n","\n","# Fit the model\n","model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n","\n","# Final evaluation of the model\n","scores = model.evaluate(X_test, y_test, verbose=0)\n","print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DkY2PUu6IhH6","executionInfo":{"status":"ok","timestamp":1654166554554,"user_tz":-480,"elapsed":30616,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"c85d9cd9-5c88-45cc-c5d6-0e783a3e1cf2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","300/300 [==============================] - 33s 108ms/step - loss: 0.2465 - accuracy: 0.9295 - val_loss: 0.0787 - val_accuracy: 0.9780\n","Epoch 2/10\n","300/300 [==============================] - 32s 106ms/step - loss: 0.0735 - accuracy: 0.9781 - val_loss: 0.0514 - val_accuracy: 0.9834\n","Epoch 3/10\n","300/300 [==============================] - 32s 107ms/step - loss: 0.0522 - accuracy: 0.9847 - val_loss: 0.0413 - val_accuracy: 0.9867\n","Epoch 4/10\n","300/300 [==============================] - 32s 107ms/step - loss: 0.0423 - accuracy: 0.9871 - val_loss: 0.0384 - val_accuracy: 0.9883\n","Epoch 5/10\n","300/300 [==============================] - 32s 107ms/step - loss: 0.0340 - accuracy: 0.9891 - val_loss: 0.0385 - val_accuracy: 0.9862\n","Epoch 6/10\n","300/300 [==============================] - 32s 106ms/step - loss: 0.0275 - accuracy: 0.9918 - val_loss: 0.0331 - val_accuracy: 0.9896\n","Epoch 7/10\n","300/300 [==============================] - 32s 106ms/step - loss: 0.0225 - accuracy: 0.9930 - val_loss: 0.0331 - val_accuracy: 0.9895\n","Epoch 8/10\n","300/300 [==============================] - 32s 106ms/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 0.0374 - val_accuracy: 0.9872\n","Epoch 9/10\n","300/300 [==============================] - 32s 105ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 0.0355 - val_accuracy: 0.9885\n","Epoch 10/10\n","300/300 [==============================] - 32s 107ms/step - loss: 0.0139 - accuracy: 0.9955 - val_loss: 0.0353 - val_accuracy: 0.9891\n","CNN Error: 1.09%\n"]}]},{"cell_type":"markdown","source":["###FULL CODE"],"metadata":{"id":"BTcAp4r5IobY"}},{"cell_type":"code","source":["# Simple CNN for the MNIST Dataset\n","import numpy\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import Flatten\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.utils import np_utils\n","\n","# fix dimension ordering issue\n","from keras import backend as K\n","#The latest version has replaced the image_dim_ordering to image_data_format.\n","#K.set_image_dim_ordering( 'th' )\n","#channel_last = (batch_size, height, width, channels) --> tf\n","K.set_image_data_format('channels_last')\n","\n","# fix random seed for reproducibility\n","seed = 7\n","numpy.random.seed(seed)\n","\n","# load data\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","# change to(batch_size, height, width, channels) --> tf\n","# height = 1, width = 28, channels=28\n","# reshape to be [samples][channels][width][height]\n","X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype( 'float32' )\n","X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype( 'float32' )\n","\n","# normalize inputs from 0-255 to 0-1\n","X_train = X_train / 255\n","X_test = X_test / 255\n","\n","# one hot encode outputs\n","y_train = np_utils.to_categorical(y_train)\n","y_test = np_utils.to_categorical(y_test)\n","num_classes = y_test.shape[1]\n","\n","# define a simple CNN model\n","def baseline_model():\n","  # create model\n","  model = Sequential()\n","  # change to(batch_size, height, width, channels) --> tf\n","  # height = 1, width = 28, channels=28\n","  #model.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation= 'relu' )) --> this is channels_first, th\n","  model.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation= 'relu' ))\n","  model.add(MaxPooling2D(pool_size=(2, 2)))\n","  model.add(Dropout(0.2))\n","  model.add(Flatten())\n","  model.add(Dense(128, activation= 'relu' ))\n","  model.add(Dense(num_classes, activation= 'softmax' ))\n","  # Compile model\n","  model.compile(loss= 'categorical_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n","  return model\n","\n","# build the model\n","model = baseline_model()\n","\n","# Fit the model\n","model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n","\n","# Final evaluation of the model\n","scores = model.evaluate(X_test, y_test, verbose=0)\n","print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"afHDGWW_Ip22","executionInfo":{"status":"ok","timestamp":1654167651008,"user_tz":-480,"elapsed":325343,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"ab913af3-2e3e-4837-9ed9-fb5e9b2f8201"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","300/300 [==============================] - 34s 111ms/step - loss: 0.2543 - accuracy: 0.9275 - val_loss: 0.0919 - val_accuracy: 0.9723\n","Epoch 2/10\n","300/300 [==============================] - 32s 107ms/step - loss: 0.0788 - accuracy: 0.9764 - val_loss: 0.0522 - val_accuracy: 0.9824\n","Epoch 3/10\n","300/300 [==============================] - 32s 106ms/step - loss: 0.0531 - accuracy: 0.9836 - val_loss: 0.0480 - val_accuracy: 0.9829\n","Epoch 4/10\n","300/300 [==============================] - 32s 106ms/step - loss: 0.0417 - accuracy: 0.9869 - val_loss: 0.0385 - val_accuracy: 0.9878\n","Epoch 5/10\n","300/300 [==============================] - 32s 106ms/step - loss: 0.0339 - accuracy: 0.9896 - val_loss: 0.0385 - val_accuracy: 0.9872\n","Epoch 6/10\n","300/300 [==============================] - 32s 106ms/step - loss: 0.0287 - accuracy: 0.9910 - val_loss: 0.0349 - val_accuracy: 0.9886\n","Epoch 7/10\n","300/300 [==============================] - 32s 106ms/step - loss: 0.0240 - accuracy: 0.9925 - val_loss: 0.0360 - val_accuracy: 0.9871\n","Epoch 8/10\n","300/300 [==============================] - 32s 105ms/step - loss: 0.0203 - accuracy: 0.9933 - val_loss: 0.0313 - val_accuracy: 0.9884\n","Epoch 9/10\n","300/300 [==============================] - 32s 106ms/step - loss: 0.0164 - accuracy: 0.9950 - val_loss: 0.0332 - val_accuracy: 0.9885\n","Epoch 10/10\n","300/300 [==============================] - 32s 106ms/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.0357 - val_accuracy: 0.9886\n","CNN Error: 1.14%\n"]}]},{"cell_type":"markdown","source":["##19.5 Larger Convolutional Neural Network for MNIST"],"metadata":{"id":"D1rsYejbJB8t"}},{"cell_type":"code","source":["# Larger CNN for the MNIST Dataset\n","import numpy\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import Flatten\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.utils import np_utils\n","from keras import backend as K\n","#The latest version has replaced the image_dim_ordering to image_data_format.\n","#K.set_image_dim_ordering( 'th' )\n","K.set_image_data_format('channels_last')\n","\n","# fix random seed for reproducibility\n","seed = 7\n","numpy.random.seed(seed)\n","\n","# load data\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","# reshape to be [samples][pixels][width][height]\n","X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype( 'float32' )\n","X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype( 'float32' )\n","\n","# normalize inputs from 0-255 to 0-1\n","X_train = X_train / 255\n","X_test = X_test / 255\n","\n","# one hot encode outputs\n","y_train = np_utils.to_categorical(y_train)\n","y_test = np_utils.to_categorical(y_test)\n","num_classes = y_test.shape[1]\n","\n","# define the larger model\n","def larger_model():\n","# create model\n","  model = Sequential()\n","  model.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation= 'relu' ))\n","  model.add(MaxPooling2D(pool_size=(2, 2)))\n","  model.add(Conv2D(15, (3, 3), activation= 'relu' ))\n","  model.add(MaxPooling2D(pool_size=(2, 2)))\n","  model.add(Dropout(0.2))\n","  model.add(Flatten())\n","  model.add(Dense(128, activation= 'relu' ))\n","  model.add(Dense(50, activation= 'relu' ))\n","  model.add(Dense(num_classes, activation= 'softmax' ))\n","  # Compile model\n","  model.compile(loss= 'categorical_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n","  return model\n","\n","# build the model\n","model = larger_model()\n","\n","# Fit the model\n","model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n","\n","# Final evaluation of the model\n","scores = model.evaluate(X_test, y_test, verbose=0)\n","print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))"],"metadata":{"id":"O3I6tEH2JNdl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654168124034,"user_tz":-480,"elapsed":451403,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"73f1876d-8f8d-4c26-baf0-02c09e37a796"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","300/300 [==============================] - 47s 154ms/step - loss: 0.3825 - accuracy: 0.8806 - val_loss: 0.0757 - val_accuracy: 0.9771\n","Epoch 2/10\n","300/300 [==============================] - 38s 127ms/step - loss: 0.0972 - accuracy: 0.9700 - val_loss: 0.0510 - val_accuracy: 0.9837\n","Epoch 3/10\n","300/300 [==============================] - 38s 128ms/step - loss: 0.0718 - accuracy: 0.9776 - val_loss: 0.0421 - val_accuracy: 0.9869\n","Epoch 4/10\n","300/300 [==============================] - 39s 131ms/step - loss: 0.0594 - accuracy: 0.9811 - val_loss: 0.0375 - val_accuracy: 0.9876\n","Epoch 5/10\n","300/300 [==============================] - 38s 128ms/step - loss: 0.0501 - accuracy: 0.9845 - val_loss: 0.0288 - val_accuracy: 0.9897\n","Epoch 6/10\n","300/300 [==============================] - 38s 127ms/step - loss: 0.0442 - accuracy: 0.9862 - val_loss: 0.0273 - val_accuracy: 0.9912\n","Epoch 7/10\n","300/300 [==============================] - 38s 128ms/step - loss: 0.0385 - accuracy: 0.9880 - val_loss: 0.0296 - val_accuracy: 0.9902\n","Epoch 8/10\n","300/300 [==============================] - 38s 127ms/step - loss: 0.0353 - accuracy: 0.9887 - val_loss: 0.0263 - val_accuracy: 0.9916\n","Epoch 9/10\n","300/300 [==============================] - 38s 127ms/step - loss: 0.0317 - accuracy: 0.9898 - val_loss: 0.0243 - val_accuracy: 0.9912\n","Epoch 10/10\n","300/300 [==============================] - 38s 126ms/step - loss: 0.0291 - accuracy: 0.9902 - val_loss: 0.0235 - val_accuracy: 0.9920\n","Large CNN Error: 0.80%\n"]}]}]}